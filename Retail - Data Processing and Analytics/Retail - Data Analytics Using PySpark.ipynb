{"cells":[{"cell_type":"code","source":["# Check if all required files are added\ndisplay(dbutils.fs.ls(\"dbfs:/FileStore/tables/Data/\"))"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":true,"cellMetadata":{},"nuid":"2b082aea-1b32-4558-83de-8818be87b53f","inputWidgets":{},"title":"Data Analytics using PySpark And SQL for Retail Store"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"overflow":false,"datasetInfos":[],"data":[["dbfs:/FileStore/tables/Data/Customers/","Customers/",0,0],["dbfs:/FileStore/tables/Data/Order_Items/","Order_Items/",0,0],["dbfs:/FileStore/tables/Data/Orders/","Orders/",0,0],["dbfs:/FileStore/tables/Data/denormalized/","denormalized/",0,0],["dbfs:/FileStore/tables/Data/final/","final/",0,0]],"plotOptions":{"displayType":"table","customPlotOptions":{},"pivotColumns":null,"pivotAggregation":null,"xColumns":null,"yColumns":null},"columnCustomDisplayInfos":{},"aggType":"","isJsonSchema":true,"removedWidgets":[],"aggSchema":[],"schema":[{"name":"path","type":"\"string\"","metadata":"{}"},{"name":"name","type":"\"string\"","metadata":"{}"},{"name":"size","type":"\"long\"","metadata":"{}"},{"name":"modificationTime","type":"\"long\"","metadata":"{}"}],"aggError":"","aggData":[],"addedWidgets":{},"metadata":{},"dbfsResultPath":null,"type":"table","aggOverflow":false,"aggSeriesLimitReached":false,"arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .table-result-container {\n    max-height: 300px;\n    overflow: auto;\n  }\n  table, th, td {\n    border: 1px solid black;\n    border-collapse: collapse;\n  }\n  th, td {\n    padding: 5px;\n  }\n  th {\n    text-align: left;\n  }\n</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>path</th><th>name</th><th>size</th><th>modificationTime</th></tr></thead><tbody><tr><td>dbfs:/FileStore/tables/Data/Customers/</td><td>Customers/</td><td>0</td><td>0</td></tr><tr><td>dbfs:/FileStore/tables/Data/Order_Items/</td><td>Order_Items/</td><td>0</td><td>0</td></tr><tr><td>dbfs:/FileStore/tables/Data/Orders/</td><td>Orders/</td><td>0</td><td>0</td></tr><tr><td>dbfs:/FileStore/tables/Data/denormalized/</td><td>denormalized/</td><td>0</td><td>0</td></tr><tr><td>dbfs:/FileStore/tables/Data/final/</td><td>final/</td><td>0</td><td>0</td></tr></tbody></table></div>"]}}],"execution_count":0},{"cell_type":"code","source":["# Create Dataframes for Customers,Orders and Order_Items.\n# We need to define schema while creating dataframes\n\ncustomers_df = spark.read.csv('dbfs:/FileStore/tables/Data/Customers/part_00000',schema=\"\"\"customer_id INT,customer_fname STRING,customer_lname STRING,customer_email STRING,customer_password STRING,customer_street STRING,customer_city STRING,customer_state STRING,customer_zipcode INT\"\"\")\n\norders_df = spark.read.csv('dbfs:/FileStore/tables/Data/Orders/part_00000', schema=\"\"\"order_id INT,order_date DATE,order_customer_id INT,order_status STRING\"\"\")\n\norder_items_df = spark.read.csv('dbfs:/FileStore/tables/Data/Order_Items/part_00000', schema=\"\"\"order_item_id INT,order_item_order_id INT,order_item_product_id INT,order_item_quantity INT,order_item_subtotal FLOAT,order_item_product_price FLOAT\"\"\")"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"458114f1-9172-4a6c-b2ce-50a8a02f6b7b","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["# View dataframe\ncustomers_df.show(2)\norders_df.show(2)\norder_items_df.show(2)"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"b3f04a5a-2b6a-4c03-b055-e7313a259ba2","inputWidgets":{},"title":""}},"outputs":[{"output_type":"stream","output_type":"stream","name":"stdout","text":["+-----------+--------------+--------------+--------------+-----------------+--------------------+-------------+--------------+----------------+\n|customer_id|customer_fname|customer_lname|customer_email|customer_password|     customer_street|customer_city|customer_state|customer_zipcode|\n+-----------+--------------+--------------+--------------+-----------------+--------------------+-------------+--------------+----------------+\n|          1|       Richard|     Hernandez|     XXXXXXXXX|        XXXXXXXXX|  6303 Heather Plaza|  Brownsville|            TX|           78521|\n|          2|          Mary|       Barrett|     XXXXXXXXX|        XXXXXXXXX|9526 Noble Embers...|    Littleton|            CO|           80126|\n+-----------+--------------+--------------+--------------+-----------------+--------------------+-------------+--------------+----------------+\nonly showing top 2 rows\n\n+--------+----------+-----------------+---------------+\n|order_id|order_date|order_customer_id|   order_status|\n+--------+----------+-----------------+---------------+\n|       1|2013-07-25|            11599|         CLOSED|\n|       2|2013-07-25|              256|PENDING_PAYMENT|\n+--------+----------+-----------------+---------------+\nonly showing top 2 rows\n\n+-------------+-------------------+---------------------+-------------------+-------------------+------------------------+\n|order_item_id|order_item_order_id|order_item_product_id|order_item_quantity|order_item_subtotal|order_item_product_price|\n+-------------+-------------------+---------------------+-------------------+-------------------+------------------------+\n|            1|                  1|                  957|                  1|             299.98|                  299.98|\n|            2|                  2|                 1073|                  1|             199.99|                  199.99|\n+-------------+-------------------+---------------------+-------------------+-------------------+------------------------+\nonly showing top 2 rows\n\n"]}],"execution_count":0},{"cell_type":"markdown","source":["### Join Tables into new DataFrame(Order_Details) to create new denormalized dataframe.\n##### Join1: Customer with Orders"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"99e45fc2-8b21-4c9a-a63a-5b547b7cd926","inputWidgets":{},"title":""}}},{"cell_type":"code","source":["customers_orders_df = customers_df.join(orders_df, customers_df[\"customer_id\"] == orders_df[\"order_customer_id\"])"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"6bf7a4e3-e593-4810-9317-af38d3a97acd","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["##### Select The Joined Data"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"d758b31f-01ca-4e92-903d-1fcff5b3ddb4","inputWidgets":{},"title":""}}},{"cell_type":"code","source":["customers_orders_df.select('customer_id','customer_fname','customer_lname','order_id','order_date','order_status').orderBy('customer_id').show(20)"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"9a482bf2-4bea-45cb-874f-4416714ed001","inputWidgets":{},"title":""}},"outputs":[{"output_type":"stream","output_type":"stream","name":"stdout","text":["+-----------+--------------+--------------+--------+----------+---------------+\n|customer_id|customer_fname|customer_lname|order_id|order_date|   order_status|\n+-----------+--------------+--------------+--------+----------+---------------+\n|          1|       Richard|     Hernandez|   22945|2013-12-13|       COMPLETE|\n|          2|          Mary|       Barrett|   15192|2013-10-29|PENDING_PAYMENT|\n|          2|          Mary|       Barrett|   33865|2014-02-18|       COMPLETE|\n|          2|          Mary|       Barrett|   57963|2013-08-02|        ON_HOLD|\n|          2|          Mary|       Barrett|   67863|2013-11-30|       COMPLETE|\n|          3|           Ann|         Smith|   22646|2013-12-11|       COMPLETE|\n|          3|           Ann|         Smith|   23662|2013-12-19|       COMPLETE|\n|          3|           Ann|         Smith|   35158|2014-02-26|       COMPLETE|\n|          3|           Ann|         Smith|   46399|2014-05-09|     PROCESSING|\n|          3|           Ann|         Smith|   56178|2014-07-15|        PENDING|\n|          3|           Ann|         Smith|   57617|2014-07-24|       COMPLETE|\n|          3|           Ann|         Smith|   61453|2013-12-14|       COMPLETE|\n|          4|          Mary|         Jones|    9023|2013-09-19|       COMPLETE|\n|          4|          Mary|         Jones|    9704|2013-09-24|       COMPLETE|\n|          4|          Mary|         Jones|   17253|2013-11-09|PENDING_PAYMENT|\n|          4|          Mary|         Jones|   37878|2014-03-15|       COMPLETE|\n|          4|          Mary|         Jones|   49339|2014-05-28|       COMPLETE|\n|          4|          Mary|         Jones|   51157|2014-06-10|         CLOSED|\n|          5|        Robert|        Hudson|   13705|2013-10-18|       COMPLETE|\n|          5|        Robert|        Hudson|   36472|2014-03-06|     PROCESSING|\n+-----------+--------------+--------------+--------+----------+---------------+\nonly showing top 20 rows\n\n"]}],"execution_count":0},{"cell_type":"markdown","source":["##### Consolidating order_id,order_date,order_status to structure data type"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"c3452831-be2b-4e92-8002-7ff8776ff1d0","inputWidgets":{},"title":""}}},{"cell_type":"code","source":["from pyspark.sql.functions import struct\ncustomers_orders_df.select('customer_id', struct('order_id','order_date','order_status').alias('order_details')).orderBy('customer_id').show(10, truncate=False)"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"55aa7166-141b-4a83-b1a9-4daeee6c57bc","inputWidgets":{},"title":""}},"outputs":[{"output_type":"stream","output_type":"stream","name":"stdout","text":["+-----------+------------------------------------+\n|customer_id|order_details                       |\n+-----------+------------------------------------+\n|1          |{22945, 2013-12-13, COMPLETE}       |\n|2          |{33865, 2014-02-18, COMPLETE}       |\n|2          |{15192, 2013-10-29, PENDING_PAYMENT}|\n|2          |{57963, 2013-08-02, ON_HOLD}        |\n|2          |{67863, 2013-11-30, COMPLETE}       |\n|3          |{35158, 2014-02-26, COMPLETE}       |\n|3          |{57617, 2014-07-24, COMPLETE}       |\n|3          |{22646, 2013-12-11, COMPLETE}       |\n|3          |{23662, 2013-12-19, COMPLETE}       |\n|3          |{56178, 2014-07-15, PENDING}        |\n+-----------+------------------------------------+\nonly showing top 10 rows\n\n"]}],"execution_count":0},{"cell_type":"markdown","source":["##### Generate an array of struct field using order_details\n##### Then grouping by customer_id and storing the order_details in the form of array"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"0e2faf27-25e5-4c11-add8-7e3f52a9ae55","inputWidgets":{},"title":""}}},{"cell_type":"code","source":["customer_order_struct = customers_orders_df.select('customer_id', struct('order_id','order_date','order_status').alias('order_details'))\n\nfrom pyspark.sql.functions import collect_list\n\nfinal_df = customer_order_struct.groupBy('customer_id').agg(collect_list('order_details').alias('order_details')).orderBy('customer_id')"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"1063b8bb-e1eb-4b11-89df-10e7109a6d43","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["final_df.show(2, truncate=False)"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"01a47e89-6162-40fa-aab7-e3814597ba96","inputWidgets":{},"title":""}},"outputs":[{"output_type":"stream","output_type":"stream","name":"stdout","text":["+-----------+----------------------------------------------------------------------------------------------------------------------------------+\n|customer_id|order_details                                                                                                                     |\n+-----------+----------------------------------------------------------------------------------------------------------------------------------+\n|1          |[{22945, 2013-12-13, COMPLETE}]                                                                                                   |\n|2          |[{15192, 2013-10-29, PENDING_PAYMENT}, {33865, 2014-02-18, COMPLETE}, {57963, 2013-08-02, ON_HOLD}, {67863, 2013-11-30, COMPLETE}]|\n+-----------+----------------------------------------------------------------------------------------------------------------------------------+\nonly showing top 2 rows\n\n"]}],"execution_count":0},{"cell_type":"markdown","source":["##### Export Dataframe to JSON"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"2c1e2c5e-f19c-422c-a80a-7f36399d952f","inputWidgets":{},"title":""}}},{"cell_type":"code","source":["final_df.coalesce(1).write.json('dbfs:/FileStore/tables/Data/final')"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"734e5c81-2f3c-4c91-9cc5-9cd9f3826969","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["display(dbutils.fs.ls(\"dbfs:/FileStore/tables/Data/\"))"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"51ad2152-b10b-4f12-9145-d11cd3da54fe","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"overflow":false,"datasetInfos":[],"data":[["dbfs:/FileStore/tables/Data/Customers/","Customers/",0,0],["dbfs:/FileStore/tables/Data/Order_Items/","Order_Items/",0,0],["dbfs:/FileStore/tables/Data/Orders/","Orders/",0,0],["dbfs:/FileStore/tables/Data/final/","final/",0,0]],"plotOptions":{"displayType":"table","customPlotOptions":{},"pivotColumns":null,"pivotAggregation":null,"xColumns":null,"yColumns":null},"columnCustomDisplayInfos":{},"aggType":"","isJsonSchema":true,"removedWidgets":[],"aggSchema":[],"schema":[{"name":"path","type":"\"string\"","metadata":"{}"},{"name":"name","type":"\"string\"","metadata":"{}"},{"name":"size","type":"\"long\"","metadata":"{}"},{"name":"modificationTime","type":"\"long\"","metadata":"{}"}],"aggError":"","aggData":[],"addedWidgets":{},"metadata":{},"dbfsResultPath":null,"type":"table","aggOverflow":false,"aggSeriesLimitReached":false,"arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .table-result-container {\n    max-height: 300px;\n    overflow: auto;\n  }\n  table, th, td {\n    border: 1px solid black;\n    border-collapse: collapse;\n  }\n  th, td {\n    padding: 5px;\n  }\n  th {\n    text-align: left;\n  }\n</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>path</th><th>name</th><th>size</th><th>modificationTime</th></tr></thead><tbody><tr><td>dbfs:/FileStore/tables/Data/Customers/</td><td>Customers/</td><td>0</td><td>0</td></tr><tr><td>dbfs:/FileStore/tables/Data/Order_Items/</td><td>Order_Items/</td><td>0</td><td>0</td></tr><tr><td>dbfs:/FileStore/tables/Data/Orders/</td><td>Orders/</td><td>0</td><td>0</td></tr><tr><td>dbfs:/FileStore/tables/Data/final/</td><td>final/</td><td>0</td><td>0</td></tr></tbody></table></div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["#### Now, we perform denormalization for all 3 tables i.e. Customers, Orders and Order_Details"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"96589845-0c4b-4402-894d-630839284ab9","inputWidgets":{},"title":""}}},{"cell_type":"code","source":["### Joing the tables\ncustomer_details = customers_df.join(orders_df, customers_df[\"customer_id\"] == orders_df[\"order_customer_id\"]). \\\n                               join(order_items_df, orders_df[\"order_id\"] == order_items_df[\"order_item_order_id\"])\n\n## Create a Denormalized Data Frame by combining all the required field under order_detail as Struct Data Type.\n\ndenormalized_df = customer_details. \\\nselect('customer_id','customer_fname','customer_lname','customer_email','order_id','order_date','order_status',struct('order_item_id','order_item_product_id','order_item_subtotal').alias('order_item_details')). \\\ngroupBy('customer_id','customer_fname','customer_lname','customer_email','order_id','order_date','order_status'). \\\nagg(collect_list('order_item_details').alias('order_item_details')). \\\norderBy('customer_id'). \\\nselect('customer_id','customer_fname','customer_lname','customer_email',struct('order_id','order_date','order_status','order_item_details').alias('order_details')). \\\ngroupBy('customer_id','customer_fname','customer_lname','customer_email'). \\\nagg(collect_list('order_details').alias('order_details')). \\\norderBy('customer_id')\n\n"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"17ef6530-710a-4a53-8d1a-db6e2dc54489","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["#####Export Dataframe to JSON"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"48ca9f0c-e04d-46b5-8d23-67b70c45194f","inputWidgets":{},"title":""}}},{"cell_type":"code","source":["denormalized_df.coalesce(1).write.json('dbfs:/FileStore/tables/Data/denormalized')"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"573baa14-4d14-42b1-a069-afca0858b46c","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["#### Perform The Analysis On Our Data"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"c9ad0aa1-7029-4830-8683-4fbd9b7af415","inputWidgets":{},"title":""}}},{"cell_type":"markdown","source":["#### Step:1 Read The Data"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"09dd3094-91cf-44cf-9fd7-fefc6f80a04e","inputWidgets":{},"title":""}}},{"cell_type":"code","source":["# We will read our json denormalized data first\njson_df = spark.read.json('dbfs:/FileStore/tables/Data/denormalized/part-00000-tid-9052100391716899340-7ab94b77-0613-4544-964c-f7fd4f5d205b-134-1-c000.json')\njson_df.show(2)"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"39fa5a4c-6ff2-4742-9a9d-8828269baad9","inputWidgets":{},"title":""}},"outputs":[{"output_type":"stream","output_type":"stream","name":"stdout","text":["+--------------+--------------+-----------+--------------+--------------------+\n|customer_email|customer_fname|customer_id|customer_lname|       order_details|\n+--------------+--------------+-----------+--------------+--------------------+\n|     XXXXXXXXX|       Richard|          1|     Hernandez|[{2013-12-13, 229...|\n|     XXXXXXXXX|          Mary|          2|       Barrett|[{2013-08-02, 579...|\n+--------------+--------------+-----------+--------------+--------------------+\nonly showing top 2 rows\n\n"]}],"execution_count":0},{"cell_type":"markdown","source":["#### Step 2: Perform Analysis:\n##### 1- Get the Details of the order placed by the customer on 2013 December 25th (Christmas) and 2013 Decmeber 31st (New Year Eve)"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"cea6bc78-3e14-44b7-aeca-c4de60389d19","inputWidgets":{},"title":""}}},{"cell_type":"code","source":["# Christmas Order Details\nfrom pyspark.sql.functions import explode\n\njson_df.select('customer_id','customer_fname',explode('order_details').alias('order_details')). \\\nfilter('order_details.order_date LIKE \"2013-12-25%\"'). \\\norderBy('customer_id'). \\\nselect('customer_id','customer_fname','order_details.order_id','order_details.order_date','order_details.order_status'). \\\nshow(10)\n"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"f9ce2b31-cf02-47ea-9ca5-0fd8bbcad28b","inputWidgets":{},"title":""}},"outputs":[{"output_type":"stream","output_type":"stream","name":"stdout","text":["+-----------+--------------+--------+----------+---------------+\n|customer_id|customer_fname|order_id|order_date|   order_status|\n+-----------+--------------+--------+----------+---------------+\n|         12|   Christopher|   24642|2013-12-25| PAYMENT_REVIEW|\n|         53|     Katherine|   24704|2013-12-25|        PENDING|\n|        119|          Mary|   24672|2013-12-25|     PROCESSING|\n|        255|          Mary|   24640|2013-12-25|       COMPLETE|\n|        258|         Aaron|   24705|2013-12-25|       COMPLETE|\n|        326|       Shirley|   61759|2013-12-25|       COMPLETE|\n|        347|         Bryan|   61738|2013-12-25|        PENDING|\n|        454|        Robert|   61771|2013-12-25|PENDING_PAYMENT|\n|        483|          Mary|   24775|2013-12-25|       COMPLETE|\n|        594|          Mary|   24696|2013-12-25|PENDING_PAYMENT|\n+-----------+--------------+--------+----------+---------------+\nonly showing top 10 rows\n\n"]}],"execution_count":0},{"cell_type":"code","source":["# New Year Eve Order Details\njson_df.select('customer_id','customer_fname',explode('order_details').alias('order_details')). \\\nfilter('order_details.order_date LIKE \"2013-12-31%\"'). \\\norderBy('customer_id'). \\\nselect('customer_id','customer_fname','order_details.order_id','order_details.order_date','order_details.order_status'). \\\nshow(10)"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"1bb3a9b9-32e3-4e77-aac5-c56c9b8b9b28","inputWidgets":{},"title":""}},"outputs":[{"output_type":"stream","output_type":"stream","name":"stdout","text":["+-----------+--------------+--------+----------+---------------+\n|customer_id|customer_fname|order_id|order_date|   order_status|\n+-----------+--------------+--------+----------+---------------+\n|         21|       William|   25802|2013-12-31|PENDING_PAYMENT|\n|         42|         Ethan|   25843|2013-12-31|PENDING_PAYMENT|\n|         67|      Samantha|   25722|2013-12-31|PENDING_PAYMENT|\n|         79|          Mary|   25645|2013-12-31|PENDING_PAYMENT|\n|         94|          Mary|   61886|2013-12-31|       COMPLETE|\n|        119|          Mary|   25684|2013-12-31|         CLOSED|\n|        145|          Joan|   61890|2013-12-31|         CLOSED|\n|        175|        Ronald|   25835|2013-12-31|        PENDING|\n|        211|          Mary|   25727|2013-12-31|       COMPLETE|\n|        285|       Shirley|   25855|2013-12-31|PENDING_PAYMENT|\n+-----------+--------------+--------+----------+---------------+\nonly showing top 10 rows\n\n"]}],"execution_count":0},{"cell_type":"markdown","source":["##### 2- Calculate Monthly Customer Revenue"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"1525bdef-41f7-48e9-a071-b2dc74e35acb","inputWidgets":{},"title":""}}},{"cell_type":"code","source":["# First we need to flatten our struct order details\nfrom pyspark.sql.functions import col\n\nflatten = json_df.select('customer_id','customer_fname',explode('order_details').alias('order_details')). \\\nselect('customer_id','customer_fname',col('order_details.order_date').alias('order_date'),col('order_details.order_id').alias('order_id'),col('order_details.order_status').alias('order_status'),explode('order_details.order_item_details').alias('order_item_details')). \\\nselect('customer_id','customer_fname','order_date','order_id','order_status','order_item_details.order_item_id','order_item_details.order_item_product_id','order_item_details.order_item_subtotal')"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"4912d8e0-622d-462e-b5ff-7bc2b4621c85","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["flatten.show(10)"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"cebd2bc6-d285-4b45-9e71-c7a5b0f6067b","inputWidgets":{},"title":""}},"outputs":[{"output_type":"stream","output_type":"stream","name":"stdout","text":["+-----------+--------------+----------+--------+---------------+-------------+---------------------+-------------------+\n|customer_id|customer_fname|order_date|order_id|   order_status|order_item_id|order_item_product_id|order_item_subtotal|\n+-----------+--------------+----------+--------+---------------+-------------+---------------------+-------------------+\n|          1|       Richard|2013-12-13|   22945|       COMPLETE|        57439|                  191|             499.95|\n|          2|          Mary|2013-08-02|   57963|        ON_HOLD|       145023|                 1014|             149.94|\n|          2|          Mary|2013-08-02|   57963|        ON_HOLD|       145022|                 1014|              99.96|\n|          2|          Mary|2013-08-02|   57963|        ON_HOLD|       145021|                  627|             199.95|\n|          2|          Mary|2013-08-02|   57963|        ON_HOLD|       145020|                 1073|             199.99|\n|          2|          Mary|2013-08-02|   57963|        ON_HOLD|       145019|                  365|             119.98|\n|          2|          Mary|2014-02-18|   33865|       COMPLETE|        84538|                  502|               50.0|\n|          2|          Mary|2014-02-18|   33865|       COMPLETE|        84537|                 1073|             199.99|\n|          2|          Mary|2014-02-18|   33865|       COMPLETE|        84536|                  957|             299.98|\n|          2|          Mary|2013-10-29|   15192|PENDING_PAYMENT|        38007|                 1014|              99.96|\n+-----------+--------------+----------+--------+---------------+-------------+---------------------+-------------------+\nonly showing top 10 rows\n\n"]}],"execution_count":0},{"cell_type":"code","source":["# After Flattening, now lets compute customer monthly revenue\nfrom pyspark.sql.functions import to_date,date_format,sum as _sum\nfrom pyspark.sql import Row\n\nflatten.select('customer_id','customer_fname',col(\"order_date\"),to_date(col(\"order_date\"), \"yyyy-MM-dd\").alias(\"order_date_converted\"),'order_status','order_item_subtotal'). \\\nfilter('order_status IN (\"COMPLETE\", \"CLOSED\")').\\\ngroupBy('customer_id','customer_fname',date_format('order_date_converted','yyy-MM').alias('order_month')). \\\nagg(_sum('order_item_subtotal').alias('Revenue')). \\\norderBy('order_month'). \\\nshow()"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"dfae8d24-2cfe-49a3-87c8-5e7abb03e254","inputWidgets":{},"title":""}},"outputs":[{"output_type":"stream","output_type":"stream","name":"stdout","text":["+-----------+--------------+-----------+------------------+\n|customer_id|customer_fname|order_month|           Revenue|\n+-----------+--------------+-----------+------------------+\n|       1478|          Anna|    2013-07|           1784.76|\n|       1180|          Mary|    2013-07|           1129.94|\n|         16|       Tiffany|    2013-07|             39.99|\n|       2418|         Helen|    2013-07|1099.8400000000001|\n|        943|          John|    2013-07| 829.8900000000001|\n|       1104|         Linda|    2013-07|            699.96|\n|       1265|        Albert|    2013-07|            199.99|\n|        965|          Sean|    2013-07|494.95000000000005|\n|       1932|       Shirley|    2013-07| 929.9100000000001|\n|        121|          Mary|    2013-07| 609.9300000000001|\n|         66|          Mary|    2013-07| 749.9300000000001|\n|       2129|       William|    2013-07|            589.91|\n|        137|      Jonathan|    2013-07|229.98000000000002|\n|       2321|          Mary|    2013-07|            279.93|\n|        948|      Michelle|    2013-07|            739.95|\n|        460|       Vincent|    2013-07|            393.92|\n|       1049|          Mary|    2013-07|            549.94|\n|        553|        Eugene|    2013-07|289.95000000000005|\n|         76|        Joseph|    2013-07|             849.9|\n|        446|         Scott|    2013-07|299.90999999999997|\n+-----------+--------------+-----------+------------------+\nonly showing top 20 rows\n\n"]}],"execution_count":0},{"cell_type":"markdown","source":["##### 3- Calculate Monthly Revenue"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"28362163-1fc1-4f14-adc7-24098b176f95","inputWidgets":{},"title":""}}},{"cell_type":"code","source":["### Lets compute Monthly revenue\nflatten.select('customer_id','customer_fname',col(\"order_date\"),to_date(col(\"order_date\"), \"yyyy-MM-dd\").alias(\"order_date_converted\"),'order_status','order_item_subtotal'). \\\nfilter('order_status IN (\"COMPLETE\", \"CLOSED\")').\\\ngroupBy(date_format('order_date_converted','yyy-MM').alias('order_month')). \\\nagg(_sum('order_item_subtotal').alias('Revenue')). \\\norderBy('order_month'). \\\nshow()"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"a6b8f1c1-ad77-4b84-b278-2b798c556444","inputWidgets":{},"title":""}},"outputs":[{"output_type":"stream","output_type":"stream","name":"stdout","text":["+-----------+------------------+\n|order_month|           Revenue|\n+-----------+------------------+\n|    2013-07| 333465.4500000003|\n|    2013-08|1221828.9000000027|\n|    2013-09|1302255.8000000028|\n|    2013-10|1171686.9200000018|\n|    2013-11|1379935.3300000008|\n|    2013-12| 1277719.600000003|\n|    2014-01|1230221.7400000019|\n|    2014-02|1217770.0900000029|\n|    2014-03|1271350.9700000028|\n|    2014-04|1249723.5200000028|\n|    2014-05|1221679.3300000022|\n|    2014-06|1179754.0600000035|\n|    2014-07| 955590.7700000018|\n+-----------+------------------+\n\n"]}],"execution_count":0},{"cell_type":"markdown","source":["#### Conclusion: In this project, we denormalized Data Tables and use PySpark to perform Analysis."],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"1d9dc60d-c9ca-4f11-b6c0-cff4ce46f8a5","inputWidgets":{},"title":""}}},{"cell_type":"code","source":[""],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"19a33a30-12c5-4ad4-b5e4-6ba059d2f634","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0}],"metadata":{"application/vnd.databricks.v1+notebook":{"notebookName":"Retail - Data Analytics Using PySpark","dashboards":[],"notebookMetadata":{"pythonIndentUnit":4},"language":"python","widgets":{},"notebookOrigID":3862533904039528}},"nbformat":4,"nbformat_minor":0}
